{
	"Type": "CHECKPOINT TRAINED",
	"NSFW": "True",
	"Update_Date":"Jan 10, 2024",
	"Base": "SDXL 1.0",
	"Links": "https://civitai.work/models/260267/animagine-xl-v3?modelVersionId=293564",
	"Version": "v3.0",
	"Tags": "BASE MODEL ANIME",
	"Usage_Tips": "STEPS: 132,590 EPOCHS: 10",
	"Author": "CagliostroLab Gold SDXL Badge",
	"ReMark": "Overview Animagine XL 3.0 is the latest version of the sophisticated open-source anime text-to-image model, building upon the capabilities of its predecessor, Animagine XL 2.0. Developed based on Stable Diffusion XL, this iteration boasts superior image generation with notable improvements in hand anatomy, efficient tag ordering, and enhanced knowledge about anime concepts. Unlike the previous iteration, we focused to make the model learn concepts rather than aesthetic.Animagine XL 3.0 was trained on a 2x A100 GPU with 80GB memory for 21 days or over 500 gpu hours. For further information please visit our official blog or huggingface repository.Model Details Developed by: Cagliostro Research Lab Model type: Diffusion-based text-to-image generative modelModel Description: Animagine XL 3.0 is engineered to generate high-quality anime images from textual prompts. It features enhanced hand anatomy, better concept understanding, and prompt interpretation, making it the most advanced model in its series.License: Fair AI Public License 1.0-SDFinetuned from model: Animagine XL 2.0 Usage Guidelines Tag Ordering Prompting is a bit different in this iteration, for optimal results, it's recommended to follow the structured prompt template because we train the model like this: 1girl/1boy, character name, from what series, everything else in any order.Special Tags Like the previous iteration, this model was trained with some special tags to steer the result toward quality, rating and when the posts was created. The model can still do the job without these special tags, but it’s recommended to use them if we want to make the model easier to handle，Recommended settings To guide the model towards generating high-aesthetic images, use negative prompts like: nsfw, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name For higher quality outcomes, prepend prompts with: masterpiece, best quality However, be careful to use masterpiece, best quality because many high-scored datasets are NSFW. It’s better to add nsfw, rating: sensitive to the negative prompt and rating: general to the positive prompt. it’s recommended to use a lower classifier-free guidance (CFG Scale) of around 5-7, sampling steps below 30, and to use Euler Ancestral (Euler a) as a sampler"
}