webui_global_lang_ui = "lang_EN"
webui_global_server_name = True
webui_global_server_port = 7860
webui_global_inbrowser = False
webui_global_auth = False
webui_global_auth_message = "Welcome to webui !"
webui_global_share = False
webui_global_steps_max = 100
webui_global_batch_size_max = 4
webui_global_width_max_img_create = 4096
webui_global_height_max_img_create = 4096
webui_global_width_max_img_modify = 8192
webui_global_height_max_img_modify = 8192
webui_global_sd15_width = 512
webui_global_sd15_height = 512
webui_global_sdxl_width = 1024
webui_global_sdxl_height = 1024
webui_global_gfpgan = True
webui_global_tkme = 0.6
webui_global_clipskip = 0
webui_global_ays = False
webui_global_img_fmt = "png"
webui_global_text_metadatas = True
webui_global_img_exif = True
webui_global_gif_exif = True
webui_global_mp4_metadatas = True
webui_global_audio_metadatas = True
light_mode = "Switch to light mode and reload page"
dark_mode = "Switch to dark mode and reload page"
about = "About"
about_infos = "Informations"
about_module = "Module : "
about_function = "Function : "
about_inputs = "Input(s) : "
about_input_text = "Input text"
about_input_image = "Input image"
about_input_prompt = "Prompt"
about_input_prompt_neg = "Prompt, negative prompt"
about_input_img_prompt_neg = "Input image, prompt, negative prompt"
about_outputs = "Output(s) : "
about_output_text = "Output text"
about_modelpage = "HF model page : "
about_help = "Help"
about_usage = "Usage :"
about_models = "Models :"
about_lora = "LoRA models :"
about_examples = "Examples : "
factory_settings = "Settings"
model_label = "Model"
model_info = "Choose model to use for inference"
maxtoken_label = "Max tokens"
maxtoken_info = "Maximum number of tokens to generate"
seed_label = "Seed(0 for random)"
seed_info = "Seed to use for generation. Depending on scheduler, may permit reproducibility"
stream_label = "Stream"
stream_info = "Stream results"
ctx_label = "n_ctx"
ctx_info = "Maximum context size"
penalty_label = "Repeat penalty"
penalty_info = "The penalty to apply to repeated tokens"
temperature_label = "Temperature"
temperature_info = "Temperature to use for sampling"
top_p_label = "top_p"
top_p_info = "The top-p value to use for sampling"
top_k_label = "top_k"
top_k_info = "The top-k value to use for sampling"
prompt_template_label = "Prompt template"
prompt_template_info = "Place your custom prompt template here. Keep the {prompt} and {system} tags, they will be replaced by your prompt and system template."
system_template_label = "System template"
system_template_info = "Place your custom system template here."
steps_label = "Steps"
steps_info = "Number of iterations per image. Results and speed depends of sampler"
sampler_label = "Sampler"
sampler_info = "Sampler to use for inference"
cfgscale_label = "CFG scale"
cfgscale_info = "Low values : more creativity. High values : more fidelity to the prompts"
imgcfg_label = "Img CFG Scale"
batch_size_label = "Batch size"
batch_size_image_info = "Number of images to generate in a single run"
batch_count_label = "Batch count"
batch_count_info = "Number of batch to run successively"
image_width_label = "Image Width"
image_width_info = "Width of outputs"
image_height_label = "Image Height"
image_height_info = "Height of outputs"
audio_length_label = "Audio length (sec)"
audio_sampling_label = "Use sampling"
video_length_label = "Video Length (frames)"
video_length_info = "Number of frames in the output video"
video_fps_label = "Frames per second"
video_fps_info = "Number of frames per second"
video_width_label = "Video Width"
video_height_label = "Video Height"
video_steps_info = "Number of iterations per video. Results and speed depends of sampler"
threeD_frame_size_label = "Frame size"
threeD_frame_size_info = "Size of the outputs"
gfpgan_label = "Use GFPGAN to restore faces"
gfpgan_info = "Use GFPGAN to enhance faces in the outputs"
tkme_label = "Token merging ratio"
tkme_info = "0=slow,best quality, 1=fast,worst quality"
clipskip_label = "CLIP skip"
clipskip_info = "Numbers of CLIP layers to skip (SD 1.5 only)"
lora_label = "LoRA model"
lora_info = "Choose LoRA model to use for inference"
lora_weight_label = "LoRA weight"
lora_weight_info = "Weight of the LoRA model in the final result"
textinv_label = "Textual inversion"
textinv_info = "Choose textual inversion to use for inference"
save_settings = "Save custom defaults settings"
delete_settings = "Delete custom defaults settings"
save_settings_msg = "Settings saved"
delete_settings_msg = "Settings deleted"
chatbot_prompt_label = "Input"
chatbot_prompt_placeholder = "Type your request here ..."
chatbot_history = "Chatbot history"
img_input_label = "Input image"
prompt_label = "Prompt"
negprompt_label = "Negative Prompt"
input_type_label = "Input type"
input_type_info = "Choose input type"
input_language_label = "Input language"
input_language_info = "Select input language"
output_language_label = "Output language"
output_language_info = "Select output language"
image_denoising_label = "Denoising strength"
image_denoising_info = "Balance between input image (0) and prompts (1)"
image_prompt_info = "Describe what you want in your image"
image_prompt_placeholder = "a cute kitten playing with a ball, dynamic pose, close-up cinematic still, photo realistic, ultra quality, 4k uhd, perfect lighting, HDR, bokeh"
image_negprompt_info = "Describe what you DO NOT want in your image"
image_negprompt_placeholder = "out of frame, bad quality, medium quality, blurry, ugly, duplicate, text, characters, logo"
image_zip = "Zip gallery"
image_zip_file = "Output"
audio_prompt_label = "Describe your music"
audio_prompt_placeholder = "90s rock song with loud guitars and heavy drums"
image_gallery_label = "Generated images"
audio_generated_label = "Generated music"
video_generated_label = "Generated video"
video_generated_gif_label="Generated gif"
threeD_generated_label = "Generated object"
output_type_label = "Output type"
output_type_info = "Choose output type"
generate = "Generate"
factory_continue = "Continue"
cancel = "Cancel"
clear_inputs = "Clear inputs"
clear_outputs = "Clear outputs"
download_chat = "Download full conversation"
send_label = "Send ..."
send_text_value= "... text module ..."
send_image_value = "... image module ..."
send_audio_value = "... audio module ..."
send_video_value = "... video module ..."
send_3d_value = "... 3d module ..."
send_output_value = "... output text to ..."
send_sel_output_value = "... selected output to ..."
send_input_prompt_value = "... input prompt(s) to ..."
send_both_value = "... both to ..."
## SPECIFIC TO MODULES :
## TEXT MODULES
tab_text = "Text"
tab_text_chatbot_send_output_value = "... last chatbot reply to ..."
## CHATBOT LLAMACPP
tab_llamacpp = "Chatbot Llama-cpp (gguf)"
tab_llamacpp_about_desc = "Chat with an AI using "
tab_llamacpp_about_instruct = "- Type your request in the <b>Input</b> textbox field</br>\
- (optional) modify settings to use another model, change context size or modify maximum number of tokens generated.</br>\
- Click the <b>Generate</b> button to generate a response to your input, using the chatbot history to keep a context.</br>\
- Click the <b>Continue</b> button to complete the last reply."
tab_llamacpp_about_models_inst1 = "You could place llama-cpp compatible .gguf models in the directory ./biniou/models/llamacpp. Restart Biniou to see them in the models list."
tab_llamacpp_about_models_inst2 = "You can also copy/paste in the <b>Model</b> dropdown menu a HF repo ID (e.g : TheBloke/some_model-GGUF) from https://huggingface.co/models?sort=trending&search=thebloke+gguf. You must also set manually prompt and system templates according to the model page."
tab_llamacpp_model_info = "Choose model to use for inference or copy/paste a HF repo id. Manually set quantization, prompt and system templates according to model page."
tab_llamacpp_quantization_label = "Quantization"
tab_llamacpp_quantization_info = "Paste here the name of the quantized gguf file to use. Leave blank to use default (may fail for customs models)"
tab_llamacpp_force_prompt_label = "Force prompt template"
tab_llamacpp_force_prompt_info = "Choose prompt template to use for inference"
# LLAVA
tab_llava = "Llava (gguf)"
tab_llava_about_desc = "Interrogate a chatbot about an input image using "
tab_llava_about_input_value = "Input image, Input text"
tab_llava_about_instruct = "- Upload or import an <b>Input image</b></br>\
- Type your request in the <b>Input</b> textbox field</br>\
- (optional) modify settings to use another model, change context size or modify maximum number of tokens generated.</br>\
- Click the <b>Generate</b> button to generate a response to your input, using the chatbot history to keep a context.</br>\
- Click the <b>Continue</b> button to complete the last reply."
tab_llava_about_models_inst1 = "You could place llama-cpp compatible .gguf models in the directory ./biniou/models/llava. Restart Biniou to see them in the models list."
tab_llava_template_prompt_info="Place your custom prompt template here. Keep the {prompt} tag, that will be replaced by your prompt."
# IMAGE CAPTIONING
tab_img2txt_git = "Image captioning"
tab_img2txt_about_desc = "Caption an image by a simple description of it using GIT"
tab_img2txt_about_input_text = "Input image"
tab_img2txt_about_output_text = "Caption text"
tab_img2txt_about_instruct = "- Upload an input image by clicking on the <b>Input image</b> field</br>\
- (optional) modify settings to use another model, change min. and/or max. number of tokens generated.</br>\
- Click the <b>Generate button</b></br>\
- After generation, captions of the image are displayed in the Generated captions field"
tab_img2txt_min_tokens_label = "Min tokens"
tab_img2txt_min_tokens_info = "Minimum number of tokens in output"
tab_img2txt_num_beams_label = "Num beams"
tab_img2txt_num_beams_info = "Number of total beams"
tab_img2txt_gr_beams_label = "Num beam groups"
tab_img2txt_gr_beams_info = "Number of beam groups"
tab_img2txt_penalty_label = "Diversity penalty"
tab_img2txt_penalty_info = "Penalty score value for a beam"
tab_img2txt_captions = "Generated captions"
# WHISPER
tab_whisper = "Whisper"
tab_whisper_about_desc = "Transcribe/translate audio to text with "
tab_whisper_about_input_text = "Input audio"
tab_whisper_about_output_text = "Transcribed/translated text"
tab_whisper_about_instruct = "- Upload an input audio file by clicking on the <b>Source audio</b> field or select the <b>micro</b> input type and record your voice</br>\
- Select the source language of the audio</br>\
- Select the task to execute : transcribe in source language or translate to english</br>\
- (optional) modify settings to use another model, or generate SRT-formated subtitles</br>\
- Click the <b>Generate</b> button</br>\
- After generation, audio transcription is displayed in the <b>Output text</b> field"
tab_whisper_srt_output_label = ".srt format output"
tab_whisper_srt_output_info = "Generate an output in .srt format"
tab_whisper_src_audio_label = "Audio source"
tab_whisper_output_type_label = "Task"
tab_whisper_output_type_info = "Choose task to execute"
tab_whisper_output_text = "Output text"
# NLLB
tab_nllb = "Nllb translation"
tab_nllb_about_desc = "Translate text with "
tab_nllb_about_output_text = "Translated text"
tab_nllb_about_instruct = "- Select an <b>input language</b></br>\
- Type or copy/paste the text to translate in the <b>source text</b> field</br>\
- Select an <b>output language</b></br>\
- (optional) modify settings to use another model, or reduce the maximum number of tokens in the output</br>\
- Click the <b>Generate</b> button</br>\
- After generation, translation is displayed in the <b>Output text</b> field"
tab_nllb_src_text_label = "Source text"
tab_nllb_src_text_placeholder = "Type or paste here the text to translate"
tab_nllb_output_text = "Output text"
# PROMPT GENERATOR
tab_txt2prompt = "Prompt generator"
tab_txt2prompt_about_desc = "Create complex prompt from a simple instruction."
tab_txt2prompt_about_output_text = "Enhanced output prompt"
tab_txt2prompt_about_instruct = "- Define a <b>prompt</b></br>\
- Choose the type of output to produce : ChatGPT will produce a persona for the chatbot from your input, SD will generate a prompt usable for image and video modules</br>\
- Click the <b>Generate</b> button</br>\
- After generation, output is displayed in the <b>Output text</b> field. Send them to the desired module (chatbot or media modules)."
tab_txt2prompt_batch_size_info = "Number of prompts to generate"
tab_txt2prompt_prompt_placeholder = "a doctor"
tab_txt2prompt_output_type_info = "Choose type of prompt to generate"
tab_txt2prompt_output_text = "Output prompt"
## IMAGES MODULES
tab_image = "Image"
tab_image_about_desc = "Generate images from a prompt and a negative prompt using "
tab_image_about_output_text = "Image(s)"
tab_image_about_models_inst1 = "You could place huggingface.co or civitai.com Stable diffusion based safetensors models in the directory biniou/models/Stable Diffusion. Restart Biniou to see them in the models list."
tab_image_about_lora_inst1 = "You could place huggingface.co or civitai.com Stable diffusion based safetensors LoRA models in the directory biniou/models/lora/SD or biniou/models/lora/SDXL (depending on the LoRA model type : SD 1.5 or SDXL). Restart Biniou to see them in the models list."
tab_image_ays_label = "AYS scheduler optimization"
tab_image_ays_info = "Optimize scheduler (forces inference settings to 10 steps/DPM++ SDE or Euler)"

# STABLE DIFFUSION
tab_txt2img_sd = "Stable Diffusion"
tab_txt2img_sd_about_instruct = "- (optional) Modify the settings to use another model, generate several images in a single run or change dimensions of the outputs</br>\
- (optional) Select a LoRA model and set its weight</br>\
- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
# KANDINSKY
tab_txt2img_kd = "Kandinsky"
tab_txt2img_kd_about_instruct = "- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- (optional) Modify the settings to use another model, generate several images in a single run or change dimensions of the outputs</br>\
- Click the <b>generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
tab_txt2img_kd_prompt_placeholder = "An alien cheeseburger creature eating itself, claymation, cinematic, moody lighting"
tab_txt2img_kd_negprompt_placeholder = "low quality, bad quality"
# LCM
tab_txt2img_lcm = "LCM"
tab_txt2img_lcm_about_desc = "Generate images from a prompt using "
tab_txt2img_lcm_about_instruct = "- (optional) Modify the settings to generate several images in a single run or change dimensions of the outputs</br>\
- (optional) Select a LoRA model and set its weight</br>\
- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery.</br>"
tab_txt2img_lcm_origin_label = "LCM origin steps"
tab_txt2img_lcm_origin_info = "LCM origin steps"
tab_txt2img_lcm_prompt_placeholder = "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k"
# MIDJOURNEY-MINI
tab_txt2img_mjm = "Midjourney-mini"
tab_txt2img_mjm_about_instruct = "- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- (optional) Modify the settings to generate several images in a single run or change dimensions of the outputs</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
# PIXART-ALPHA
tab_txt2img_paa = "PixArt-Alpha"
tab_txt2img_paa_about_instruct = "- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- (optional) Modify the settings to use another model, generate several images in a single run or change dimensions of the outputs</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
tab_txt2img_paa_prompt_placeholder = "A small cactus with a happy face in the Sahara desert."
# IMG2IMG
tab_img2img = "Img2img"
tab_img2img_about_desc = "Generate images variations of an input image, from a prompt and a negative prompt using "
tab_img2img_about_desc_com = "You could use this module to refine an image produced by another module."
tab_img2img_about_instruct = "- (optional) Modify the settings to use another model, generate several images in a single run</br>\
- (optional) Select a LoRA model and set its weight</br>\
- Upload, import an image or draw a sketch as an <b>Input image</b></br>\
- Set the balance between the input image and the prompt (<b>denoising strength</b>) to a value between 0 and 1 : 0 will completely ignore the prompt, 1 will completely ignore the input image</br>\
- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
# IP-ADAPTER
tab_img2img_ip = "IP-Adapter"
tab_img2img_ip_about_desc = "Transform an input image, with a conditional IP-Adapter image, a prompt and a negative prompt using "
tab_img2img_ip_about_input_text = "Input image, conditional IP-Adapter image, prompt, negative prompt"
tab_img2img_ip_about_instruct = "- (optional) Modify the settings to use another model or generate several images in a single run</br>\
- (optional) Select a LoRA model and set its weight</br>\
- Select the IP-Adapter type to use : standard (image to image + prompt) or composition (import composition into the output image)</br>\
- Upload or import an image as an <b>Input image</b> (if using standard IP-Adapter)</br>\
- Upload an image as an <b>IP-Adapter image</b></br>\
- Set the balance between the input image and the prompts (Ip-Adapter image, prompts, negative prompt) by choosing a <b>denoising strength</b> value between 0.01 and 1 : 0.01 will mostly ignore the prompts, 1 will completely ignore the input image</br>\
- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery.</br>"
tab_img2img_ip_src_type_label = "IP-Adapter type"
tab_img2img_ip_src_type_info = "Choose IP-Adapter type"
tab_img2img_ip_prompt_placeholder = "wearing sunglasses, high quality"
tab_img2img_ip_negprompt_placeholder = "low quality, medium quality, blurry"
tab_img2img_ip_img_ipa = "IP-Adapter image"
# IMAGE VARIATION
tab_img2var = "Image variation"
tab_img2var_about_desc = "Generate variations of an input image using "
tab_img2var_about_instruct = "- Upload or import an image as an <b>Input image</b></br>\
- (optional) Modify the settings to generate several images in a single run</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
# PIX2PIX
tab_pix2pix = "Instruct pix2pix"
tab_pix2pix_about_desc = "Edit an input image with instructions from a prompt and a negative prompt using "
tab_pix2pix_about_instruct = "- Upload or import an image using the <b>Input image</b> field</br>\
- Fill the <b>prompt</b> with the instructions for modifying your input image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- (optional) Modify the settings to change image CFG scale or generate several images in a single run</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery</br></br>"
tab_pix2pix_imgcfg_info = "Low values : more creativity. High values : more fidelity to the input image"
tab_pix2pix_prompt_info = "Describe what you want to modify in your input image"
tab_pix2pix_prompt_placeholder = "make it a Rembrandt painting"
tab_pix2pix_negprompt_info = "Describe what you DO NOT want in your output image"
# MAGICMIX
tab_magicmix = "MagicMix"
tab_magicmix_about_desc = "Edit an input image with instructions from a prompt using "
tab_magicmix_about_input_img_prompt = "Input image, prompt"
tab_magicmix_about_instruct = "- Upload or import an image using the <b>Input image</b> field</br>\
- Adjust the <b>Mix Factor</b> slider to create a balance between input image and prompt</br>\
- Fill the <b>prompt</b> with the instructions for modifying your input image. Use simple prompt instruction (e.g. 'a dog')</br>\
- (optional) Modify the settings to generate several images in a single run or generate several images in a single run</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery</br></br>"
tab_magicmix_kmin_label = "Kmin"
tab_magicmix_kmin_info = "Controls the number of steps during the content generation process"
tab_magicmix_kmax_label = "Kmax"
tab_magicmix_kmax_info = "Determines how much information is kept in the layout of the original image"
tab_magicmix_factor_label = "Mix Factor"
tab_magicmix_factor_info = "Determines how much influence the prompt has on the layout generation"
tab_magicmix_prompt_info = "Describe how you want to modify your input image"
tab_magicmix_prompt_placeholder = "a bed"
# INPAINT
tab_inpaint = "Inpaint"
tab_inpaint_about_desc = "Inpaint the masked area of an input image, from a prompt and a negative prompt using "
tab_inpaint_about_input_text = "Input image, inpaint masked area, prompt, negative prompt"
tab_inpaint_about_instruct = "- Upload or import an image using the <b>Input image</b> field</br>\
- Using the sketch tool of the <b>inpaint field</b>, mask the area to be modified</br>\
- Modify the <b>denoising strength of the inpainted area</b> : 0 will keep the original content, 1 will ignore it</br>\
- Fill <b>the prompt</b> with what you want to see in your WHOLE (not only the inpaint area) output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- (optional) Modify the settings to use another model or generate several images in a single run</br>\
- Click the <b>Generate button</b></br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."

# PAINT BY EXAMPLE
tab_paintbyex = "Paint by example"
tab_paintbyex_about_desc = "Paint the masked area of an input image, from an example image using "
tab_paintbyex_about_input_text = "Input image, masked area, example image"
tab_paintbyex_about_instruct = "- Upload or import an image using the <b>Input image</b> field</br>\
- Using the sketch tool of the <b>Input image field</b>, mask the area to be modified</br>\
- Upload or import an example image using the <b>Example image</b> field. This image will be used as an example on how to modify the masked area of the input image</br>\
- (optional) Modify the settings to generate several images in a single run</br>\
- Click the <b>Generate button</b></br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
tab_paintbyex_imgex_label = "Example image"
# OUTPAINT
tab_outpaint = "Outpaint"
tab_outpaint_about_desc = "Outpaint an input image, by defining borders and using a prompt and a negative prompt, with "
tab_outpaint_about_input_text = "Input image, outpaint mask, prompt, negative prompt"
tab_outpaint_about_instruct = "- Upload or import an image using the <b>Input image</b> field</br>\
- Define the size in pixels of the borders to add for top, bottom, left and right sides</br>\
- Click the <b>Create mask</b> button to add borders to your image and generate a mask</br>\
- Modify the <b>denoising strength of the outpainted area</b> : 0 will keep the original content, 1 will ignore it</br>\
- Fill <b>the prompt</b> with what you want to see in your WHOLE (not only the outpaint area) output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- (optional) Modify the settings to use another model or generate several images in a single run</br>\
- Click the <b>Generate button</b></br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
tab_outpaint_top_label = "Top"
tab_outpaint_top_info = "Pixels to add on top"
tab_outpaint_bottom_label = "Bottom"
tab_outpaint_bottom_info = "Pixels to add on bottom"
tab_outpaint_mask_btn = "Create mask"
tab_outpaint_mask_img = "Mask preview"
tab_outpaint_left_label = "Left"
tab_outpaint_left_info = "Pixels to add on left"
tab_outpaint_right_label = "Right"
tab_outpaint_right_info = "Pixels to add on right"
# CONTROLNET
tab_controlnet = "ControlNet"
tab_controlnet_about_desc = "Generate images from a prompt, a negative prompt and a control image using "
tab_controlnet_about_input_text = "Prompt, negative prompt, ControlNet input"
tab_controlnet_about_instruct = "- (optional) Modify the settings to use another model, change the settings for ControlNet or adjust threshold on canny</br>\
- (optional) Select a LoRA model and set its weight</br>\
- Select a <b>Source image</b> that will be used to generate the control image</br>\
- Select a <b>pre-processor</b> for the control image</br>\
- Click the <b>Preview</b> button</br>\
- If the <b>Control image</b> generated suits your needs, continue. Else, you could modify the settings and generate a new one</br>\
- You should not modifiy the value in the <b>ControlNet Model</b> field, as it is automatically selected from the used pre-processor</br>\
- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- Click the <b>Generate button</b></br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery</br>"
tab_controlnet_lowthres_label = "Canny low threshold"
tab_controlnet_lowthres_info = "ControlNet Low threshold"
tab_controlnet_highthres_label = "Canny high threshold"
tab_controlnet_highthres_info = "ControlNet high threshold"
tab_controlnet_strength_label = "ControlNet strength"
tab_controlnet_strength_info = "ControlNet strength"
tab_controlnet_start_label = "Start ControlNet"
tab_controlnet_start_info = "Start ControlNet at % step"
tab_controlnet_stop_label = "Stop ControlNet"
tab_controlnet_stop_info = "Stop ControlNet at % step"
tab_controlnet_src_img = "Source image"
tab_controlnet_prepro_label = "Pre-processor"
tab_controlnet_prepro_info = "Choose pre-processor to use"
tab_controlnet_preview_btn = "Preview"
tab_controlnet_preview_img = "Control image preview"
tab_controlnet_variant_label = "ControlNet Model"
tab_controlnet_variant_info = "Choose ControlNet model to use"
tab_controlnet_preview_clear = "Clear preview"
# PHOTOBOOTH
tab_faceid_ip = "Photobooth"
tab_faceid_ip_about_desc = "Generate portraits using the face taken from the input image, a prompt and a negative prompt using "
tab_faceid_ip_about_instruct = "- (optional) Modify the settings to use another model, generate several images in a single run</br>\
- (optional) Select a LoRA model and set its weight</br>\
- Upload or import an image using the <b>Input image</b> field</br>\
- Set the the input image strength : lower values give more creativity to the portrait, higher values more fidelity to the input image.</br>\
- Fill the <b>prompt</b> with what you want to see in your output image</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output image</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
tab_faceid_ip_denoising_label = "Input image strength"
tab_faceid_ip_denoising_info = "Weight of the input image in the generated image"
# FACESWAP
tab_faceswap = "Faceswap"
tab_faceswap_about_desc = "Swap faces between images (source -> target) using "
tab_faceswap_about_input_text = "Source image, target image"
tab_faceswap_about_instruct = "- Upload a <b>Source image</b>. The face(s) in this image will replaces face(s) in the target image.</br>\
- Upload or import a <b>target image</b>. The face(s) in this image will be replaced with the source one(s)</br>\
- Set the <b>source index</b> list to choose which face(s) to extract from source image and in which order. From left to right and starting from 0, id comma separated list of faces number. For example, if there is 3 faces in a picture '0,2' will select the face on the left, then on the right, but not on the one in the middle. If set to 0, take only the first face from the left.</br>\
- Set the <b>target index</b> list to choose which face(s) to replace in target image and in which order. From left to right and starting from 0, id comma separated list of faces number. For example, if there is 3 faces in a picture '2,1' will select the faces on the right, then in the middle, but not the one on the left. The source index list is used to create a mapping between the faces to extract and to replace. If set to 0, replace only the first face from the left.</br>\
- (optional) Modify the settings to desactivate GFPGAN faces restoration</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images are displayed in the gallery. Save them individually or create a downloadable zip of the whole gallery."
tab_faceswap_src_img = "Source image"
tab_faceswap_src_index_label = "Source index"
tab_faceswap_src_index_info = "Use a comma separated list of faces to export to target (numbers from left to right)"
tab_faceswap_tgt_img = "Target image"
tab_faceswap_tgt_index_label = "Target index"
tab_faceswap_tgt_index_info = "Use a comma separated list of faces to replace in target (numbers from left to right)"
# REAL ESRGAN
tab_resrgan = "Real ESRGAN"
tab_resrgan_about_desc = "Upscale x2, x4 or x8 using "
tab_resrgan_about_output_text = "Upscaled image"
tab_resrgan_about_instruct = "- Upload or import an <b>Input image</b> </br>\
- (optional) Modify the settings to change scale factor or use another model</br>\
- Click the <b>Generate</b> button</br>\
- After generation, upscaled image is displayed in the gallery."
tab_resrgan_scale_label = "Upscale factor"
tab_resrgan_scale_info = "Choose upscale factor"
tab_resrgan_width_info = "Width of input"
tab_resrgan_height_info = "Height of input"
# GFPGAN
tab_gfpgan = "GFPGAN"
tab_gfpgan_about_desc = "Restore and enhance faces in an image using "
tab_gfpgan_about_output_text = "Enhanced Image"
tab_gfpgan_about_instruct = "- Upload or import an <b>Input image</b></br>\
- (optional) Modify the settings to use another variant of the GFPGAN model</br>\
- Click the <b>Generate</b> button</br>\
- After generation, enhanced image is displayed in the gallery"
tab_gfpgan_variant_label = "Variant"
tab_gfpgan_variant_info = "Variant of GPFGAN to use"
## AUDIO MODULES
tab_audio = "Audio"
tab_audio_about_output_text = "Generated music"
tab_audio_steps_info = "Number of iterations per audio. Results and speed depends of sampler"
tab_audio_batch_size_info = "Number of audios to generate in a single run"
# MUSICGEN
tab_musicgen = "MusicGen"
tab_musicgen_about_desc = "Generate music from a prompt, using "
tab_musicgen_about_instruct = "- Fill the <b>prompt</b> by describing the music you want to generate</br>\
- (optional) Modify the settings to use another model or change audio duration</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated music is available to listen in the <b>Generated music<b> field."
# MUSICGEN MELODY
tab_musicgen_mel = "MusicGen Melody"
tab_musicgen_mel_about_desc = "Generate music from a prompt with guidance from an input audio, using "
tab_musicgen_mel_about_input_text = "Input prompt, Input audio"
tab_musicgen_mel_about_instruct = "- Select an audio source type (file or micro recording)</br>\
- Select an audio source by choosing a file or recording something</br>\
- Fill the <b>prompt</b> by describing the music you want to generate from the audio source</br>\
- (optional) Modify the settings to change audio duration or inferences parameters</br>\
- Click the <b>Generate<b> button</br>\
- After generation, generated music is available to listen in the <b>Generated music<b> field."
tab_musicgen_mel_src_type_label = "Source audio type"
tab_musicgen_mel_src_type_info = "Choose source audio type"
tab_musicgen_mel_src_audio = "Source audio"
# MUSICLDM
tab_musicldm = "MusicLDM"
tab_musicldm_about_desc = "Generate music from a prompt and a negative prompt, using "
tab_musicldm_about_instruct = "- Fill the <b>prompt</b> by describing the music you want to generate</br>\
- Fill the <b>negative prompt</b> by describing what you DO NOT want to generate</br>\
- (optional) Modify the settings to use another model or change audio duration</br>\
- Click the <b>Generate<b> button</br>\
- After generation, generated music is available to listen in the <b>Generated music<b> field."
tab_musicldm_length_label = "Audio length"
tab_musicldm_length_info = "Duration of audio file to generate"
tab_musicldm_prompt_info = "Describe the content of your output audio file"
tab_musicldm_prompt_placeholder = "Techno music with a strong, upbeat tempo and high melodic riffs, high quality, clear"
tab_musicldm_negprompt_info = "Describe what you DO NOT want in your output audio file"
tab_musicldm_negprompt_placeholder = "low quality, average quality"
# AUDIOGEN
tab_audiogen = "AudioGen"
tab_audiogen_about_desc = "Generate sound from a prompt, using "
tab_audiogen_about_output_text = "Generated sound"
tab_audiogen_about_instruct = "- Fill the <b>Prompt</b> by describing the sound you want to generate</br>\
- (optional) Modify the settings to change audio duration</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated sound is available to listen in the <b>Generated sound</b> field."
tab_audiogen_prompt_label = "Describe your sound"
tab_audiogen_prompt_placeholder = "dog barking, sirens of an emergency vehicle, footsteps in a corridor"
tab_audiogen_output = "Generated sound"
# HARMONAI
tab_harmonai = "Harmonai"
tab_harmonai_about_desc = "Generate audio from a specific model using "
tab_harmonai_about_instruct = "- (optional) Modify the settings to change audio duration or choose another model</br>\
- Click the <b>Generate<b> button</br>\
- After generation, generated audio is available to listen in the <b>Output<b> field."
tab_harmonai_input_text = "None"
tab_harmonai_output_text = "Generated audio"
# BARK
tab_bark = "Bark"
tab_bark_about_desc = "Generate high quality text-to-speech in several languages with "
tab_bark_about_output_text = "Generated speech"
tab_bark_about_instruct = "- Fill the <b>prompt</b> with the text you want to hear</br>\
- (optional) Modify the settings to select a model and a voice</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated audio is available to listen in the <b>Generated speech</b> field.</br>\
<b>Tips : </b>You can add modifications to the generated voices, by adding the following in your prompts :</br>\
[laughter]</br>\
[laughs]</br>\
[sighs]</br>\
[music]</br>\
[gasps]</br>\
[clears throat]</br>\
— or ... for hesitations</br>\
♪ for song lyrics</br>\
CAPITALIZATION for emphasis of a word</br>\
[MAN] and [WOMAN] to bias Bark toward male and female speakers, respectively</br>"
tab_bark_prompt_label = "Text to speech"
tab_bark_prompt_placeholder = "Type or past here what you want to hear ..."
tab_bark_output = "Generated speech"
## VIDEO MODULES
tab_video = "Video"
tab_video_about_desc = "Generate video from a prompt and a negative prompt using "
tab_video_about_output_text = "Video"
tab_video_about_instruct = "- (optional) Modify the settings to use another model, modify the number of frames to generate, fps of the output video or change dimensions of the outputs</br>\
- Fill the <b>prompt</b> with what you want to see in your output video</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output video</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated video is displayed in the <b>Generated video</b> field.</br>"
tab_video_chunks_label = "Chunk size"
tab_video_prompt_info = "Describe what you want in your video"
tab_video_negprompt_info = "Describe what you DO NOT want in your video"
tab_video_batch_size_info = "Number of videos to generate in a single run"
# MODELSCOPE
tab_txt2vid_ms = "Modelscope"
tab_txt2vid_ms_prompt_placeholder = "Darth vader is surfing on waves, photo realistic, best quality"
tab_txt2vid_ms_negprompt_placeholder = "out of frame, ugly"
# TEXT2VIDEO-ZERO
tab_txt2vid_ze = "Text2Video-Zero"
tab_txt2vid_ze_chunks_info = "Number of frames processed in a chunk. 1 = no chunks."
tab_txt2vid_ze_avd_settings = "Advanced Settings"
tab_txt2vid_ze_strengthx_label = "Motion field strength x"
tab_txt2vid_ze_strengthx_info = "Horizontal motion strength"
tab_txt2vid_ze_strengthy_label = "Motion field strength y"
tab_txt2vid_ze_strengthy_info = "Vertical motion strength"
tab_txt2vid_ze_t0_label = "Timestep t0"
tab_txt2vid_ze_t1_label = "Timestep t1"
tab_txt2vid_ze_prompt_placeholder = "a panda is playing guitar on times square"
tab_txt2vid_ze_negprompt_placeholder = "out of frame, ugly"
# ANIMATEDIFF
tab_animatediff_lcm = "AnimateDiff"
tab_animatediff_adapter_label = "Adapter"
tab_animatediff_adapter_info = "Choose adapter to use for inference"
tab_animatediff_prompt_placeholder = "A space rocket with trails of smoke behind it launching into space from the desert, 4k, high resolution"
tab_animatediff_negprompt_placeholder = "bad quality, worst quality, low resolution"
tab_animatediff_min_cfg_label = "Min guidance scale"
tab_animatediff_min_cfg_info = "CFG scale with first frame"
tab_animatediff_max_cfg_label = "Max guidance scale"
tab_animatediff_max_cfg_info = "CFG scale with last frame"
# STABLE VIDEO DIFFUSION
tab_img2vid = "Stable Video Diffusion"
tab_img2vid_about_desc = "Generate video from an input image using "
tab_img2vid_about_instruct = "- (optional) Modify the settings to use another model, modify the number of frames to generate, fps of the output video or change dimensions of the outputs</br>\
- Upload or import an input image</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated video is displayed in the <b>Generated video</b> field."
tab_img2vid_chunks_info = "Number of frames processed in a chunk"
tab_img2vid_bucket_label = "Motion bucket ID"
tab_img2vid_bucket_info = "Higher value = more motion, lower value = less motion"
tab_img2vid_noise_label = "Noise strength"
tab_img2vid_noise_info = "Higher value = more motion"
# VIDEO INSTRUCT PIX2PIX
tab_vid2vid_ze = "Video Instruct-Pix2Pix"
tab_vid2vid_ze_about_desc = "Edit an input video with instructions from a prompt and a negative prompt using "
tab_vid2vid_ze_about_input_text = "Input video, prompt, negative prompt"
tab_vid2vid_ze_about_instruct = "- Upload or import a video using the <b>Input video</b> field</br>\
- Fill the <b>prompt</b> with the instructions for modifying your input video</br>\
- Fill the <b>negative prompt</b> with what you DO NOT want to see in your output video</br>\
- (optional) Modify the settings to change the number of frames to process (default=8) or the fps of the output</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated video is displayed in the Generated video field.</br></br>"
tab_vid2vid_ze_imgcfg_info = "Low values : more creativity. High values : more fidelity to the input video"
tab_vid2vid_ze_video_length_info = "Number of frames to process"
tab_vid2vid_ze_vid_label = "Input video"
tab_vid2vid_ze_prompt_info = "Describe what you want to modify in your input video"
tab_vid2vid_ze_prompt_placeholder = "make it Van Gogh Starry Night style"
tab_vid2vid_ze_negprompt_info = "Describe what you DO NOT want in your output video"
tab_vid2vid_ze_negprompt_placeholder = "out of frame, bad quality, blurry, ugly, text, characters, logo"
# 3D
tab_3d = "3d"
tab_3d_about_output_text = "Animated gif or mesh object"
# SHAP-E TXT2SHAPE
tab_txt2shape = "Shap-E txt2shape"
tab_txt2shape_about_desc = "Generate 3d animated gif or 3d mesh object from a prompt using "
tab_txt2shape_about_instruct = "- Fill the <b>prompt</b> with what you want to see in your output</br>\
- Select the desired output type : animated Gif or 3D Model (mesh)</br>\
- (optional) Modify the settings to generate several images in a single run or change dimensions of the outputs</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images or 3D models are displayed in the output field. Save them individually or create a downloadable zip of the whole gallery."
tab_txt2shape_prompt_placeholder = "a firecracker"
# SHAP-E IMG2SHAPE
tab_img2shape = "Shap-E img2shape"
tab_img2shape_about_desc = "Generate 3d animated gif or 3d mesh object from an imput image using "
tab_img2shape_about_instruct = "- Upload or import an image using the <b>Input image</b> field. To achieve good results, objects to create should be on a white backgrounds</br>\
- Select the desired output type : animated Gif or 3D Model (mesh)</br>\
- (optional) Modify the settings to generate several images in a single run or change dimensions of the outputs</br>\
- Click the <b>Generate</b> button</br>\
- After generation, generated images or 3D models are displayed in the output field. Save them individually or create a downloadable zip of the whole gallery."
## SETTINGS
tab_settings = "Global Settings"
tab_settings_list_label = "Installed models list"
tab_settings_delete_models = "Delete selected models"
tab_settings_refresh_models = "Refresh models list"
# LOGIN
tab_login = "Global settings login"
tab_login_acc = "Identify to access Global settings"
tab_login_btn_login = "Login"
tab_login_btn_logout = "Logout"
tab_login_btn_logout_message = "Logged out"
tab_login_user_label = "Username"
tab_login_user_info = "1st line of .ini/auth.cfg is used as admin account (default=biniou)"
tab_login_pass_label = "Password"
tab_login_pass_info = "1st line of .ini/auth.cfg is used as admin account (default=biniou)"
tab_login_test_success = "Successful login : access is granted"
tab_login_test_fail = "Login failed : bad username/password"
# WEBUI
tab_webui = "WebUI control"
tab_webui_system = "System"
tab_webui_restart = "Restart biniou"
tab_webui_reload = "Reload WebUI"
tab_webui_shutdown = "Shutdown biniou"
tab_webui_update_title = "Updates and optimizations"
tab_webui_update_label = "Optimization type"
tab_webui_update_info = "Choose CPU (default) or a GPU optimization to use and click Update. You have to restart biniou and reload UI after update."
tab_webui_update_btn_label = "Update biniou"
tab_webui_backend_title = "Llama-cpp-python backend"
tab_webui_backend_label = "Llama-cpp-python backend"
tab_webui_backend_info = "Choose for which backend llama-cpp-python should be compiled. Backend must be already available and working. (default = none)"
tab_webui_backend_btn_label = "Update llama-cpp-python backend"
tab_webui_settings_title = "Common settings"
tab_webui_settings_lang_title = "Languages"
tab_webui_settings_lang_label = "Default language"
tab_webui_settings_lang_info = "Choose your default language at startup. Restart biniou and reload WebUI. (default = lang_en_US)"
tab_webui_settings_backend_title = "Backend settings"
tab_webui_settings_server_name_label = "LAN accessibility"
tab_webui_settings_server_name_info = "Uncheck to limit access of biniou to localhost only (default = True)"
tab_webui_settings_server_port_label = "Server port"
tab_webui_settings_server_port_info = "Define server port (default = 7860)"
tab_webui_settings_inbrowser_label = "Load in browser at start"
tab_webui_settings_inbrowser_info = "Open webui in browser when starting biniou (default = False)"
tab_webui_settings_auth_label = "Activate authentication"
tab_webui_settings_auth_info = "A simple user/pass authentication (default = biniou/biniou). Credentials are stored in ./.ini/auth.cfg (default = False)"
tab_webui_settings_auth_msg_label = "Login message"
tab_webui_settings_auth_msg_info = "Login screen welcome message. Authentication is required."
tab_webui_settings_share_label = "Share online"
tab_webui_settings_share_info = "Allow online access by a public link to this biniou instance. Authentication is required. (default = False)"
tab_webui_settings_image = "Images settings"
tab_webui_settings_steps_max_label = "Maximum steps"
tab_webui_settings_steps_max_info = "Maximum number of possible iterations in a generation (default=100)"
tab_webui_settings_batch_size_label = "Maximum batch size"
tab_webui_settings_batch_size_info = "Maximum value for a batch size (default=4)"
tab_webui_settings_max_w_crea_label = "Maximum image width (create)"
tab_webui_settings_max_w_crea_info = "Maximum width of outputs when using modules that create contents (default = 4096)"
tab_webui_settings_max_h_crea_label = "Maximum image height (create)"
tab_webui_settings_max_h_crea_info = "Maximum height of outputs when using modules that create contents (default = 4096)"
tab_webui_settings_max_w_mod_label = "Maximum image width (modify)"
tab_webui_settings_max_w_mod_info = "Maximum width of outputs when using modules that modify contents (default = 8192)"
tab_webui_settings_max_h_mod_label = "Maximum image height (modify)"
tab_webui_settings_max_h_mod_info = "Maximum height of outputs when using modules that modify contents (default = 8192)"
tab_webui_settings_def_w_sd15_label = "Default image width (SD 1.5 models)"
tab_webui_settings_def_w_sd15_info = "Width of outputs when using SD 1.5 models (default = 512)"
tab_webui_settings_def_h_sd15_label = "Default image height (SD 1.5 models)"
tab_webui_settings_def_h_sd15_info = "Height of outputs when using SD 1.5 models (default = 512)"
tab_webui_settings_def_w_sdxl_label = "Default image width (SDXL models)"
tab_webui_settings_def_w_sdxl_info = "Width of outputs when using SDXL models (default = 1024)"
tab_webui_settings_def_h_sdxl_label = "Default image height (SDXL models)"
tab_webui_settings_def_h_sdxl_info = "Height of outputs when using SDXL models (default = 1024)"
tab_webui_settings_gfpgan_label = "Default use of GFPGAN to restore faces"
tab_webui_settings_gfpgan_info = "Activate/desactivate gfpgan enhancement for all modules using it (default = True)"
tab_webui_settings_tkme_label = "Default token merging ratio"
tab_webui_settings_tkme_info = "Set token merging ratio for all modules using it (default = 0.6)"
tab_webui_settings_clipskip_label = "Default CLIP skip value"
tab_webui_settings_clipskip_info = "Numbers of CLIP layers to skip for all modules using it. SD 1.5 only. (default = 0)"
tab_webui_settings_ays_label = "Default use of AYS scheduler optimization"
tab_webui_settings_ays_info = "Activate/desactivate AYS enhancement for all modules using it (default = False)"
tab_webui_settings_img_fmt_label = "Default format for output images"
tab_webui_settings_img_fmt_info = "Select a default image format for outputs (default = png)"
tab_webui_settings_text_metadatas_label = "Add metadatas to text"
tab_webui_settings_text_metadatas_info = "Add generation settings to texts outputs (default = True)"
tab_webui_settings_exif_label = "Add Exif metadatas to jpg and png"
tab_webui_settings_exif_info = "Add generation settings to images metadatas (default = True)"
tab_webui_settings_gif_exif_label = "Add metadatas to gif"
tab_webui_settings_gif_exif_info = "Add generation settings to animated gif metadatas (default = True)"
tab_webui_settings_mp4_metadatas_label = "Add metadatas to mp4"
tab_webui_settings_mp4_metadatas_info = "Add generation settings to mp4 metadatas (default = True)"
tab_webui_settings_audio_metadatas_label = "Add metadatas to wav"
tab_webui_settings_audio_metadatas_info = "Add generation settings to wav metadatas (default = True)"
tab_webui_settings_saved = "Common settings saved"
tab_webui_settings_deleted = "Common settings deleted"
tab_webui_nsfw_title = "NSFW filter"
tab_webui_nsfw_label = "Use safety checker"
tab_webui_nsfw_info = "Warning : Unchecking this box will temporarily disable the safety checker which avoid generation of nsfw and disturbing media contents. This option is ONLY provided for debugging purposes and you should NEVER uncheck it in other use cases."
# MODELS CLEANER
tab_cleaner = "Models cleaner"
tab_cleaner_list_info = "Select the models you want to delete and click \"Delete selected models\" button. Restart biniou to re-synchronize models list."
# LORA MODELS
tab_lora_models = "LoRA models manager"
tab_lora_sd15_models = "SD models"
tab_lora_sdxl_models = "SDXL models"
tab_lora_models_list_info = "Select the LoRA models you want to delete and click \"Delete selected models\" button. Restart biniou to re-synchronize LoRA models list."
tab_lora_models_url_label = "LoRA model URL"
tab_lora_models_url_info = "Paste here the url of the LoRA model you want to download. Restart biniou to re-synchronize LoRA models list. Safetensors files only."
tab_lora_models_down = "Download LoRA model"
# TEXTUAL INVERSION
tab_textinv = "Textual inversion manager"
tab_textinv_sd15_models = "SD textual inversion"
tab_textinv_sdxl_models = "SDXL textual inversion"
tab_textinv_models_label = "Installed textual inversion list"
tab_textinv_models_info = "Select the textual inversion you want to delete and click \"Delete selected textual inversion\" button. Restart biniou to re-synchronize textual inversion list."
tab_textinv_delete_models = "Delete selected textual inversion"
tab_textinv_refresh_models = "Refresh textual inversion list"
tab_textinv_url_label = "Textual inversion URL"
tab_textinv_url_info = "Paste here the url of the textual inversion you want to download. Restart biniou to re-synchronize textual inversion list. Safetensors files only."
tab_textinv_down = "Download textual inversion"
# STABLE DIFFUSION MODELS
tab_sd_models = "SD models downloader"
tab_sd_models_url_label = "Stable Diffusion model URL"
tab_sd_models_url_info = "Paste here the url of the model you want to download. Restart biniou to re-synchronize models list. SDXL models must contains \"xl\" in their names to be correctly identified. Safetensors files only."
tab_sd_models_down = "Download SD model"
# GGUF MODELS
tab_gguf_models = "GGUF models downloader"
tab_gguf_models_url_label = "Chatbot Llama-cpp GGUF model URL"
tab_gguf_models_url_info = "Paste here the url of the model you want to download. Restart biniou to re-synchronize models list. gguf files only."
tab_gguf_models_down = "Download GGUF model"
## CONSOLE
console_title = "biniou console"
console_output = "biniou output"
console_down = "Download logfile"
